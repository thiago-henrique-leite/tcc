{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8Dym4vUF4Rz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3136U9E1GJQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Extrai o dataset SPIE-AAPM Lung CT Challenge do drive. O conjunto de imagens pode ser acessado no link abaixo:\n",
        "  - https://wiki.cancerimagingarchive.net/display/Public/SPIE-AAPM+Lung+CT+Challenge#19039197a19462154cc74bea92039089e61a0f44\n",
        "\"\"\"\n",
        "\n",
        "!unzip -q /content/drive/MyDrive/TCC/dataset.zip"
      ],
      "metadata": {
        "id": "1-LYdlYwGhTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "O código abaixo realiza as seguintes operações:\n",
        "  - Redimensiona as imagens para um tamanho especificado;\n",
        "  - Define um tamanho de lote para o treinamento do modelo;\n",
        "  - Divide as imagens em conjuntos de treinamento e validação;\n",
        "  - Imprime o nome das classes do dataset.\n",
        "\"\"\"\n",
        "\n",
        "IMAGE_SIZE = (180,180)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'dataset',\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=1337,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'dataset',\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=1337,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "\n",
        "train_ds.class_names"
      ],
      "metadata": {
        "id": "eHh0BgrLG9aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Esse código cria uma figura com nove subplots e plota nove imagens aleatórias do conjunto\n",
        "de treinamento do modelo - que contém tumores benignos (0) e malignos (1).\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype('uint8'))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis('off')"
      ],
      "metadata": {
        "id": "7ZOwN-UEHrJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Realiza o processo de data augmentation nas imagens:\n",
        "  - Aplica uma operação de espelhamento horizontal aleatório nas imagens de entrada;\n",
        "  - Aplica uma rotação nas imagens de entrada com uma amplitude de até 0.1 radianos.\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip('horizontal'),\n",
        "    layers.RandomRotation(0.1),\n",
        "])"
      ],
      "metadata": {
        "id": "ePtSdFA1H51e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Exibe 10 imagens do dataset após o processo de data augmentation.\n",
        "\"\"\"\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        augmented_images = data_augmentation(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "ULgIHQdvI5jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Permite que o conjunto de dados carregue 32 lotes de dados em segundo plano enquanto\n",
        "o modelo está sendo treinado com o lote anterior.\n",
        "\"\"\"\n",
        "\n",
        "BUFFER_SIZE=32\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=BUFFER_SIZE)\n",
        "val_ds = val_ds.prefetch(buffer_size=BUFFER_SIZE)"
      ],
      "metadata": {
        "id": "pxX8_6UFJAw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Constrói o modelo baseado na arquitetura Vgg19\n",
        "\"\"\"\n",
        "\n",
        "def make_model(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    x = data_augmentation(inputs)\n",
        "    x = layers.Rescaling(1.0 / 255)(x)\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(64, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    previous_block_activation = x\n",
        "\n",
        "    for size in [128, 256, 512, 728]:\n",
        "        x = layers.Activation('relu')(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation('relu')(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding='same')(previous_block_activation)\n",
        "\n",
        "        x = layers.add([x, residual])\n",
        "\n",
        "        previous_block_activation = x\n",
        "\n",
        "    x = layers.SeparableConv2D(1024, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    outputs = layers.Dense(units=1, activation='sigmoid')(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model = make_model(input_shape=IMAGE_SIZE + (3,), num_classes=2)\n",
        "\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "t-sr2HM5JuIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Executa o treinamento do modelo Vgg19\n",
        "\"\"\"\n",
        "\n",
        "EPOCHS=50\n",
        "\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\")]\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_ds, epochs=EPOCHS, callbacks=callbacks, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "WW8-IODWKP_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Método que utiliza o modelo treinado para classificar uma imagem\n",
        "\"\"\"\n",
        "\n",
        "def classify_image(image_path):\n",
        "  img = keras.preprocessing.image.load_img(image_path, target_size=IMAGE_SIZE)\n",
        "  img_array = keras.preprocessing.image.img_to_array(img)\n",
        "  img_array = tf.expand_dims(img_array, 0)\n",
        "  predictions = model.predict(img_array)\n",
        "  score = predictions[0]\n",
        "  benign = 100 * (1 - score)\n",
        "  malignant = 100 * score\n",
        "\n",
        "  print(\"This image is %.2f%% benign and %.2f%% malignant.\" % (benign, malignant))"
      ],
      "metadata": {
        "id": "8rQG36GtK6C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Testa o modelo classificando uma imagem com tumor benigno\n",
        "\"\"\"\n",
        "\n",
        "classify_image('dataset/benign/011-001.jpg')"
      ],
      "metadata": {
        "id": "OrYgZaH1K7Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Testa o modelo classificando uma imagem com tumor maligno\n",
        "\"\"\"\n",
        "\n",
        "classify_image('dataset/malignant/011-006.jpg')"
      ],
      "metadata": {
        "id": "qjwUkD-VLA1j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}