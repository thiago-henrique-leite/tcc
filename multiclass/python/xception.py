# -*- coding: utf-8 -*-
"""[MULTICLASSE] Xception.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cl_e212_3NsZhrsCjIpap9uE4jSYz5nI
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

from google.colab import drive
drive.mount('/content/drive')

!unzip -q /content/drive/MyDrive/TCC/multiclass-dataset.zip

!mkdir ndataset
!mkdir ndataset/malignant
!mkdir ndataset/benign
!mkdir ndataset/normal

!mkdir dataset
!mv benign dataset
!mv malignant dataset
!mv normal dataset

import os
from PIL import Image

dataset_dir = 'dataset'
ndataset_dir = 'ndataset'

for class_name in ['malignant', 'benign', 'normal']:
    class_dir = os.path.join(ndataset_dir, class_name)
    if not os.path.exists(class_dir):
        os.makedirs(class_dir)

for class_name in os.listdir(dataset_dir):
    class_dir = os.path.join(dataset_dir, class_name)
    if os.path.isdir(class_dir):
        for image_file in os.listdir(class_dir):
            image_path = os.path.join(class_dir, image_file)
            if os.path.isfile(image_path):
                image = Image.open(image_path)
                new_image = image.resize((224, 224))
                save_dir = os.path.join(ndataset_dir, class_name)
                save_path = os.path.join(save_dir, image_file)
                new_image.save(save_path)

directory = '/content/ndataset'

categories = ['benign', 'malignant', 'normal']

import cv2
import random
import os
import numpy as np
from collections import Counter

data = []
img_size = 224

for i in categories:
    path = os.path.join(directory, i)
    class_num = categories.index(i)
    for file in os.listdir(path):
        filepath = os.path.join(path, file)
        img = cv2.imread(filepath, 0)
        img = cv2.resize(img, (img_size, img_size))
        data.append([img, class_num])

random.shuffle(data)

X, y = [], []
for feature, label in data:
    X.append(feature)
    y.append(label)

print('X length:', len(X))
print('y counts:', Counter(y))

# normalize
X = np.array(X).reshape(-1, img_size, img_size, 1)
X = X / 255.0
y = np.array(y)

from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=10, stratify=y)
X_train = X_train.reshape(X_train.shape[0], img_size*img_size*1)

smote = SMOTE()
X_train_sampled, y_train_sampled = smote.fit_resample(X_train, y_train)

X_train = X_train.reshape(X_train.shape[0], img_size, img_size, 1)
X_train_sampled = X_train_sampled.reshape(X_train_sampled.shape[0], img_size, img_size, 1)

from keras.models import Sequential
from keras.applications.xception import Xception

X_train_rgb = np.repeat(X_train, 3, axis=3)
X_valid_rgb = np.repeat(X_valid, 3, axis=3)

base_model = Xception(include_top=False, weights='imagenet', input_shape=(img_size, img_size, 3))

model = Sequential()
model.add(base_model)
model.add(layers.GlobalAveragePooling2D())
model.add(layers.Dense(16))
model.add(layers.Rescaling(1.0 / 255))
model.add(layers.Activation('relu'))
model.add(layers.BatchNormalization())
model.add(layers.Dropout(0.5))
model.add(layers.Dense(3, activation='softmax'))

model.summary()

keras.utils.plot_model(model, show_shapes=True)

model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(1e-5), metrics=['accuracy'])

history = model.fit(X_train_rgb, y_train, batch_size=8, epochs=35, validation_data=(X_valid_rgb, y_valid))

from sklearn.metrics import classification_report, confusion_matrix

y_pred = model.predict(X_valid_rgb, verbose=1)
y_pred_bool = np.argmax(y_pred, axis=1)

print(classification_report(y_valid, y_pred_bool))

print(confusion_matrix(y_true=y_valid, y_pred=y_pred_bool))

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()